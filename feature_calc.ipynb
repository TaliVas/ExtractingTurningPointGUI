{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Data loading\n",
    "with open('df_raw_data', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df.rename(columns={'DLC_color_id':'id'}, inplace=True)\n",
    "df = df.dropna(subset=['time_milisecond', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Remove short trajectories \n",
    "def discard_short_trajectories(df, min_len):\n",
    "    return df.groupby('id').filter(lambda x: len(x) >= min_len)\n",
    "len_df = discard_short_trajectories(df, min_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Compute velocity and update movement times\n",
    "def process_dataframe(len_df):\n",
    "    \"\"\"\n",
    "    Create processed df.\n",
    "    \"\"\"\n",
    "    process_df = []\n",
    "    for trial_id in len_df['id'].unique():\n",
    "        trial = process_trial(len_df, trial_id)\n",
    "        process_df.append(trial)\n",
    "    process_df = pd.concat(process_df, ignore_index=True)\n",
    "    return process_df\n",
    "\n",
    "def process_trial(df, trial_id):\n",
    "    \"\"\"\n",
    "    Process a single trial by updating columns, computing velocity, and updating movement times.\n",
    "    \"\"\"\n",
    "    trajectory = df[df['id'] == trial_id].copy() #all data points with the same id\n",
    "    initial_start_time = trajectory.iloc[0]['start_time']\n",
    "    \n",
    "    # Adjust time columns\n",
    "    time_columns = ['start_time', 'end_time', 'cue_time', 'go_time', 'update_time', 'move_time','time_milisecond']\n",
    "    for col in time_columns:\n",
    "        trajectory[col] -= initial_start_time\n",
    "    trajectory['time_milisecond'] *= 1000\n",
    "    trajectory['cue_milisecond'] = trajectory.iloc[0]['cue_time'] * 1000\n",
    "    trajectory['go_milisecond'] = trajectory.iloc[0]['go_time'] * 1000\n",
    "    trajectory = compute_velocities(trajectory, trajectory.iloc[0]['cue_time'] * 1000)\n",
    "    return trajectory\n",
    "\n",
    "\n",
    "def compute_velocities(df, signal_cue):\n",
    "    \"\"\"\n",
    "    Calculate velocity for movements post-signal cue.\n",
    "    \"\"\"\n",
    "    # Filter and calculate differences\n",
    "    df_filtered = df[df['time_milisecond'] >= signal_cue].copy()\n",
    "    dx = df_filtered['x'].diff()\n",
    "    dy = df_filtered['y'].diff()\n",
    "    dt = df_filtered['time_milisecond'].diff()\n",
    "    \n",
    "    # Compute velocity while avoiding division by zero\n",
    "    df_filtered['velocity'] = np.sqrt(dx**2 + dy**2) / (dt + 1e-10)\n",
    "    ddx = dx.diff().fillna(0)\n",
    "    ddy = dy.diff().fillna(0)\n",
    "    df_filtered['curvature'] = (dx * ddy - dy * ddx) / (np.power(dx ** 2 + dy ** 2, 1.5) + 1e-10)\n",
    "\n",
    "    return df_filtered.iloc[1:]  # skip the first NaN result from diff()(0)\n",
    "\n",
    "processed_df = process_dataframe(len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_and_normalize_trial(trial, right_window=1500, left_window=200):\n",
    "    \"\"\"\n",
    "    Process and window a single trial.\n",
    "    \"\"\"\n",
    "    signal_go = trial.iloc[0]['go_milisecond']\n",
    "\n",
    "    # Determine the window around the go signal\n",
    "    window_start = signal_go - left_window\n",
    "    window_end = signal_go + right_window\n",
    "\n",
    "    # Filter the trial to the specified window\n",
    "    windowed_trial = trial[(trial['time_milisecond'] >= window_start) & (trial['time_milisecond'] <= window_end)].copy()\n",
    "    new_start_time = windowed_trial.iloc[0]['time_milisecond']\n",
    "\n",
    "    # Adjust times to start from zero within the window\n",
    "    windowed_trial['adjusted_time'] = windowed_trial['time_milisecond'] - new_start_time\n",
    "\n",
    "    # Normalize the adjusted times\n",
    "    max_adjusted_time = windowed_trial['adjusted_time'].max()\n",
    "    windowed_trial['normalized_time'] = windowed_trial['adjusted_time'] / max_adjusted_time\n",
    "\n",
    "    return windowed_trial\n",
    "\n",
    "def window_trials(processed_df, right_window=1500, left_window=200):\n",
    "    \"\"\"\n",
    "    Adjust times for each trial in the processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Apply the function to all trials in the dataframe\n",
    "    windowed_trials = []\n",
    "    for trial_id in processed_df['id'].unique():\n",
    "        trial = processed_df[processed_df['id'] == trial_id]\n",
    "        windowed_trial = window_and_normalize_trial(trial, right_window, left_window)\n",
    "        windowed_trials.append(windowed_trial)\n",
    "\n",
    "    return pd.concat(windowed_trials, ignore_index=True)\n",
    "\n",
    "df_windowed = window_trials(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def apply_smoothing(group, col_x='x', col_y='y', window_length=5, poly_order=1):\n",
    "    \"\"\"\n",
    "    Applies Savitzky-Golay smoothing to specified columns in a DataFrame group.\n",
    "    \"\"\"\n",
    "    # Apply the Savitzky-Golay filter\n",
    "    x_smooth = savgol_filter(group[col_x], window_length, poly_order)\n",
    "    y_smooth = savgol_filter(group[col_y], window_length, poly_order)\n",
    "\n",
    "    # Add smoothed data to new columns\n",
    "    group['smooth_x'] = x_smooth\n",
    "    group['smooth_y'] = y_smooth\n",
    "\n",
    "    return group\n",
    "\n",
    "#7. Apply smoothing to each group in the DataFrame\n",
    "df_smooth = df_windowed.groupby('id').apply(apply_smoothing)\n",
    "df_smooth = df_smooth.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recenter_trajectory(group):\n",
    "    \"\"\"\n",
    "    Recenters a trajectory group by subtracting the coordinates at the start movement time.\n",
    "    \"\"\"\n",
    "\n",
    "    initial_x_offset = group['smooth_x'].iloc[0]\n",
    "    initial_y_offset = group['smooth_y'].iloc[0]\n",
    "\n",
    "    # Apply the offset to recenter the trajectory\n",
    "    group['centered_x'] = group['smooth_x'] - initial_x_offset\n",
    "    group['centered_y'] = group['smooth_y'] - initial_y_offset\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply the recentering transformation to each trajectory \n",
    "df_centered = df_smooth.groupby('id').apply(recenter_trajectory)\n",
    "df_centered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotation(group):\n",
    "    \"\"\"\n",
    "    Applies rotation and reflection transformations to trajectory data.\n",
    "    \"\"\"\n",
    "    # Extract target ID from the first row of the group\n",
    "    id_target = group.iloc[0]['id_target']\n",
    "    # Initialize target angles for rotation\n",
    "    target_angles = {1: 270, 2: 315, 3: 0, 4: 45, 5: 90, 6: 135, 7: 180, 8: 225}\n",
    "\n",
    "    # Check for updates and obtain update target ID if present\n",
    "    is_updated = not pd.isna(group.iloc[0]['id_update'])\n",
    "    id_target_update = group.iloc[0]['id_update'] if is_updated else None\n",
    "\n",
    "    if id_target == 5:\n",
    "        if is_updated and (id_target_update > id_target):\n",
    "            # Reflect over the Y-axis if movement is not clockwise\n",
    "            group['rotation_x'],group['rotation_y']  = -group['centered_x'], group['centered_y']\n",
    "        else:\n",
    "            # No rotation needed\n",
    "            group['rotation_x'], group['rotation_y'] = group['centered_x'], group['centered_y']\n",
    "    else:\n",
    "        # General case for all other targets\n",
    "        rotation_angle = 90 - target_angles[id_target] \n",
    "        # Rotate coordinates based on computed angle\n",
    "        group['rotation_x'], group['rotation_y'] = rotate_trajectory(group['centered_x'], group['centered_y'], rotation_angle)\n",
    "        if is_updated and (id_target_update > id_target):\n",
    "            # Reflect over the Y-axis if movement is not clockwise\n",
    "            group['rotation_x'], group['rotation_y'] =  -group['centered_x'], group['centered_y']\n",
    "    return group\n",
    "\n",
    "def rotate_trajectory(x, y, angle):\n",
    "    \"\"\"\n",
    "    Rotates a point around the origin (0, 0) by a specified angle.\n",
    "    \"\"\"\n",
    "    angle_rad = np.radians(angle)\n",
    "    x_new = x * np.cos(angle_rad) - y * np.sin(angle_rad)\n",
    "    y_new = x * np.sin(angle_rad) + y * np.cos(angle_rad)\n",
    "    return x_new, y_new\n",
    "\n",
    "\n",
    "#9. Rotate trajectory data based on target alignment.\n",
    "df_rotation = df_centered.groupby('id').apply(apply_rotation)\n",
    "df_rotation = df_rotation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_targets_to_angle(id_target, id_update):\n",
    "    \"\"\"\n",
    "    Maps target IDs to angles.\n",
    "    \"\"\"\n",
    "    if not pd.isna(id_update):\n",
    "        old_target, new_target = round(id_target), round(id_update)\n",
    "        if not np.isnan(new_target):\n",
    "            target_diff = abs(new_target - old_target)\n",
    "            # Adjust for circular nature of targets.\n",
    "            if target_diff > 4:\n",
    "                target_diff = 8 - target_diff\n",
    "            angle_map = {1: 45, 2: 90, 3: 135, 4: 180}\n",
    "            return angle_map.get(target_diff, 0)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#14. Add type_angle_jump_trajectory\n",
    "df_rotation['type_trajectory'] = df_rotation.apply(lambda row: map_targets_to_angle(row['id_target'], row['id_update']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_points(group):\n",
    "    \"\"\"\n",
    "    Calculate the angles between consecutive triplets of points in the group.\n",
    "    \"\"\"\n",
    "    group['point'] = list(zip(group['rotation_x'], group['rotation_y']))\n",
    "    angles = []\n",
    "    for i in range(len(group) - 2):\n",
    "        A = group['point'].iloc[i]\n",
    "        B = group['point'].iloc[i + 1]\n",
    "        C = group['point'].iloc[i + 2]\n",
    "        angle = angle_between_three_points(A, B, C)\n",
    "        angles.append(angle)\n",
    "    # Add NaN for the last two points as they don't have enough subsequent points for the angle calculation\n",
    "    angles.extend([np.nan, np.nan])\n",
    "    group['angle'] = angles\n",
    "    return group\n",
    "\n",
    "def angle_between_three_points(A, B, C):\n",
    "    # Convert points to numpy arrays\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    C = np.array(C)\n",
    "    # Calculate vectors AB and BC\n",
    "    AB = B - A\n",
    "    BC = C - B\n",
    "    # Calculate the dot product and magnitudes of AB and BC\n",
    "    dot_product = np.dot(AB, BC)\n",
    "    magnitude_AB = np.linalg.norm(AB)\n",
    "    magnitude_BC = np.linalg.norm(BC)\n",
    "    # Calculate the cosine of the angle\n",
    "    cos_angle = dot_product / (magnitude_AB * magnitude_BC)\n",
    "    # Handle potential numerical issues\n",
    "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
    "    # Calculate the angle in radians\n",
    "    angle_radians = np.arccos(cos_angle)\n",
    "    # Convert the angle to degrees\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "    return angle_degrees\n",
    "\n",
    "# Example DataFrame (Assuming df_rotation is your DataFrame with rotated trajectories)\n",
    "df_features_angle = df_rotation.groupby('id').apply(calc_points)\n",
    "df_features_angle.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_angle_to_end(group):\n",
    "    end_x, end_y = group['rotation_x'].iloc[-1], group['rotation_y'].iloc[-1]\n",
    "    delta_x_to_end = end_x - group['rotation_x']\n",
    "    delta_y_to_end = end_y - group['rotation_y']\n",
    "    \n",
    "    start_x, start_y = group['rotation_x'].iloc[0], group['rotation_y'].iloc[0]\n",
    "    delta_x_start_to_end = end_x - start_x\n",
    "    delta_y_start_to_end = end_y - start_y\n",
    "    \n",
    "    angle_to_end = np.arctan2(delta_y_to_end, delta_x_to_end)\n",
    "    angle_start_to_end = np.arctan2(delta_y_start_to_end, delta_x_start_to_end)\n",
    "    relative_angles = np.degrees(angle_to_end - angle_start_to_end)\n",
    "    relative_angles = (relative_angles + 180) % 360 - 180\n",
    "    group['angle_to_end'] = relative_angles\n",
    "    group['distance_to_end'] = np.sqrt((group['rotation_x'] - group['rotation_x'].iloc[-1])**2 + (group['rotation_y'] - group['rotation_y'].iloc[-1])**2)\n",
    "    return group\n",
    "\n",
    "df_features_angle_to_end = df_features_angle.groupby('id').apply(calculate_relative_angle_to_end)\n",
    "df_features_angle_to_end.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. Scale X and y\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def scale_features(df, features, group_col):\n",
    "    \"\"\"\n",
    "    Scale specified features within each group defined by group_col.\n",
    "    \"\"\"\n",
    "    df_final = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    for feature in features:\n",
    "        scaled_feature = 'scaled_' + feature\n",
    "        df_final[scaled_feature] = df_final.groupby(group_col)[feature].transform(lambda group: scaler.fit_transform(group.values.reshape(-1, 1)).flatten())\n",
    "    return df_final\n",
    "\n",
    "features_to_scale = ['rotation_x', 'rotation_y','velocity', 'angle', 'angle_to_end', 'curvature','distance_to_end']\n",
    "df_final = scale_features(df_features_angle_to_end, features_to_scale, 'type_trajectory')\n",
    "df_features_final = df_final.dropna(axis=0, subset=features_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test_features_final', 'wb') as f:\n",
    "    pickle.dump((df_features_final), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
